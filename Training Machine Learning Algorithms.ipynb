{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "rnd.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have just copies the classes and functions  defined in EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin,RegressorMixin\n",
    "\n",
    "class FeaturesAdder(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"This class adds new features in the dataset.\n",
    "        Features added are : rooms_per_household, bedrooms_per_room, and population_per_household.\n",
    "    \"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X['rooms_per_household']=X['total_rooms']/X['households']\n",
    "        X['bedrooms_per_room']=X['total_bedrooms']/X['total_rooms']\n",
    "        X['population_per_household']=X['population']/X['households']\n",
    "        return X\n",
    "\n",
    "\n",
    "class RemoveOutliers(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"This class removes outliers from data.\n",
    "    Note: Outlier values are hard coded\n",
    "    \"\"\"\n",
    "    def fit (self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        X=X[(X['median_house_value']!=500001) | (X['median_income']>=2)].reset_index(drop=True)\n",
    "        X=X[X['median_income']<=11].reset_index(drop=True)\n",
    "        X=X[(X['median_house_value']!=350000) | (X['median_income']>=1.5)].reset_index(drop=True)\n",
    "        X=X[(X['median_house_value']!=450000) | (X['median_income']>=2)].reset_index(drop=True)\n",
    "        X=X[(X['median_house_value']>=350000) | (X['median_income']<=9.5)].reset_index(drop=True)\n",
    "        X=X[X['population']<=9000]\n",
    "        X=X[(X['population_per_household']>=1.15) & (X['population_per_household']<=6.5)]\n",
    "        X=X[X['rooms_per_household']<20]\n",
    "        X=X[X['bedrooms_per_room']<0.5].reset_index(drop=True)\n",
    "        return X\n",
    "    \n",
    "\n",
    "class FeaturesTransformer(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"This class trnsforms numberical featuress in the dataset.\n",
    "    Note: Transformations are hard coded.\n",
    "    \"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        import numpy as np\n",
    "        from scipy.special import boxcox1p        \n",
    "        X['total_rooms']=X['total_rooms'].apply(lambda x: boxcox1p(x,0.25))\n",
    "        X['total_bedrooms']=X['total_bedrooms'].apply(lambda x: boxcox1p(x,0.25))\n",
    "        X['households']=X['households'].apply(lambda x: boxcox1p(x,0.2))\n",
    "        X['population']=X['population'].apply(lambda x: boxcox1p(x,0.3))\n",
    "        X['rooms_per_household']=X['rooms_per_household'].apply(lambda x: np.log1p(x)**0.5)\n",
    "        X['bedrooms_per_room']=X['bedrooms_per_room'].apply(lambda x: np.log1p(x)**0.25)\n",
    "        X['median_income']=X['median_income'].apply(lambda x: np.log1p(x)**1.25)\n",
    "        X['population_per_household']=X['population_per_household'].apply(lambda x: np.log1p(x)**1)\n",
    "        return X\n",
    "    \n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"This class is a dataframe selector.\n",
    "        Data members:\n",
    "            features: A list of column_names you want in output dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self,features):\n",
    "        self.features=features\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[self.features]\n",
    "\n",
    "class GetDummies(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"This class is used to get dummy columns from categorical columns.\"\"\"\n",
    "    def fit (self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        #change ISLAND to NEAR BAY...as count of ISLAND is very low\n",
    "        X[X=='ISLAND']='NEAR BAY'\n",
    "        return (pd.get_dummies(X,drop_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_by_pvalue(X,y,pvalue=0.05):\n",
    "    \"\"\"Remove features with p-value more than 'pvalue'\n",
    "    \n",
    "    This function uses statsmodels.api.OLS model. Please add intercept to data externally.\n",
    "    Input:\n",
    "        X: Array or dataframe excluding predicted variable\n",
    "        y: Series or list of predicted variable\n",
    "        pvalue: int or float\n",
    "    \n",
    "    Note:\n",
    "        X is changed inplace\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    for i in range(len(X.columns)):\n",
    "        regressor_OLS=sm.OLS(endog=y,exog=X).fit()\n",
    "        s=regressor_OLS.pvalues.sort_values(ascending=False)\n",
    "        if s.iloc[0]>pvalue:\n",
    "            X.drop(s.index[0],axis=1,inplace=True)\n",
    "            print('Removed: ',s.index[0],'P-value: ',s.iloc[0])\n",
    "        \n",
    "def remove_by_vif(X,vif=5):\n",
    "    \"\"\"Remove columns from X whose VIF is greater than supplied 'vif'\n",
    "    Parameters:\n",
    "        X:array or dataframe containing data excluding target variable\n",
    "        vif: int or float of limiting value of VIF\n",
    "    Note:\n",
    "        This function changes X inplace\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "        \n",
    "    for i in range(len(X.columns)):\n",
    "        l = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        s=pd.Series(index=X.columns,data=l).sort_values(ascending=False)\n",
    "        if s.iloc[0]>vif:\n",
    "            X.drop(s.index[0],axis=1,inplace=True)\n",
    "            print('Removed: ',s.index[0],', VIF: ',s.iloc[0])\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Train Data Ready\n",
    "\n",
    "I have done the same operations on data as discussed in EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('strat_train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_prepared: (16005, 16)\n",
      "Length of all_features: 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load or preprocess your DataFrame\n",
    "df = pd.read_csv('strat_train_set.csv')\n",
    "\n",
    "df=FeaturesAdder().fit_transform(df)\n",
    "#Removing outliers\n",
    "df=RemoveOutliers().fit_transform(df)\n",
    "\n",
    "data_labels=df['median_house_value']\n",
    "df=df.drop('median_house_value',axis=1)\n",
    "\n",
    "# Calculate new features\n",
    "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
    "df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']\n",
    "df['population_per_household'] = df['population'] / df['households']\n",
    "\n",
    "# Define your pipeline and perform data preprocessing...\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Assuming these are the features and labels\n",
    "num_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                'total_bedrooms', 'population', 'households', 'median_income',\n",
    "                'rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
    "\n",
    "cat_features = ['ocean_proximity']\n",
    "\n",
    "# Define custom transformers\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Define the preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_features)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_features)),\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# Apply the full pipeline to your data\n",
    "X_prepared = full_pipeline.fit_transform(df)\n",
    "\n",
    "# Determine the columns after preprocessing\n",
    "cat_encoder = full_pipeline.named_transformers_['cat'].named_steps['one_hot_encoder']\n",
    "cat_one_hot_attribs = list(cat_encoder.get_feature_names_out(cat_features))\n",
    "all_cols = num_features + cat_one_hot_attribs\n",
    "\n",
    "# Check the shape of X_prepared\n",
    "print(\"Shape of X_prepared:\", X_prepared.shape)\n",
    "\n",
    "# Check the length of all_features\n",
    "print(\"Length of all_features:\", len(all_cols))\n",
    "\n",
    "# Verify if the number of columns matches the shape of the preprocessed data\n",
    "if len(all_cols) != X_prepared.shape[1]:\n",
    "    raise ValueError(\"Number of columns does not match the shape of the preprocessed data.\")\n",
    "\n",
    "# Convert the transformed array back to a DataFrame\n",
    "df_preprocessed = pd.DataFrame(X_prepared, columns=all_cols)\n",
    "data_prepared=df\n",
    "y_train=data_labels.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed DataFrame to a new CSV file\n",
    "df_preprocessed.to_csv('preprocessed_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import learning_curve,cross_val_score,validation_curve,train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(scores,param_range,param_name,scoring='r2'):\n",
    "    \"\"\"This function plot validation curve.\n",
    "    \n",
    "    Parameters:\n",
    "        scores: scores obtained from validation_curve() method\n",
    "        param_range: list of range of parameters passed as 'param_range' in validation_curve() method\n",
    "        scoring: str\n",
    "    \"\"\"\n",
    "    n=len(param_range)\n",
    "    if scoring=='r2':\n",
    "        train_score=[scores[0][i].mean() for i in range (0,n)]\n",
    "        test_score=[scores[1][i].mean() for i in range (0,n)]\n",
    "    elif scoring=='neg_mean_squared_error':\n",
    "        train_score=[np.sqrt(-scores[0][i].mean()) for i in range (0,n)]\n",
    "        test_score=[np.sqrt(-scores[1][i].mean()) for i in range (0,n)]\n",
    "\n",
    "    fig=plt.figure(figsize=(8,6))\n",
    "    plt.plot(param_range,train_score,label='Train')\n",
    "    plt.plot(param_range,test_score,label='Test')\n",
    "    plt.xticks=param_range\n",
    "    plt.title(\"Validation curve of {}\".format(param_name),size=12)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.8288666958593517\n"
     ]
    }
   ],
   "source": [
    "data_prepared = df_preprocessed\n",
    "lr=LinearRegression()\n",
    "scores=cross_val_score(lr,data_prepared,data_labels,n_jobs=-1,cv=5,scoring='r2')\n",
    "print('R2: ',np.sqrt(scores).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate RMSE I have used 'train_y' which are unscaled labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  63262.70787670886\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "scores=cross_val_score(lr,data_prepared,y_train,n_jobs=-1,cv=5,scoring='neg_mean_squared_error')\n",
    "print('RMSE: ',np.sqrt(-scores).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with linear regression,\n",
    "\n",
    "R-squared=0.8\n",
    "\n",
    "RMSE=63262.78\n",
    "\n",
    "RMSE of above model is 67960 which means that there's an average error of $67960 in prediction of house price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
